{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В якості домашнього завдання вам пропонується створити рекурентну нейронну мережу за допомогою механізмів Keras, яка буде класифікувати рецензії із датасету imdb.\n",
    "\n",
    "На відміну від прикладу в модулі 9 ми використаємо рекурентну нейронну мережу. Поекспериментуйте з будовою мережі - RNN, LSTM, двостороння та глибока.\n",
    "\n",
    "Порівняйте результати та зробіть висновки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-06 17:34:28.209988: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 167ms/step - accuracy: 0.5635 - loss: 0.6675 - val_accuracy: 0.6108 - val_loss: 0.7733\n",
      "Epoch 2/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 152ms/step - accuracy: 0.7373 - loss: 0.5361 - val_accuracy: 0.7256 - val_loss: 0.5572\n",
      "Epoch 3/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 152ms/step - accuracy: 0.8035 - loss: 0.4310 - val_accuracy: 0.7748 - val_loss: 0.5135\n",
      "Epoch 4/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 154ms/step - accuracy: 0.8418 - loss: 0.3760 - val_accuracy: 0.7166 - val_loss: 0.5957\n",
      "Epoch 5/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 168ms/step - accuracy: 0.8507 - loss: 0.3553 - val_accuracy: 0.7294 - val_loss: 0.5712\n",
      "Epoch 1/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 589ms/step - accuracy: 0.6721 - loss: 0.5998 - val_accuracy: 0.7402 - val_loss: 0.5145\n",
      "Epoch 2/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 612ms/step - accuracy: 0.8266 - loss: 0.3904 - val_accuracy: 0.8288 - val_loss: 0.3984\n",
      "Epoch 3/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 601ms/step - accuracy: 0.8538 - loss: 0.3446 - val_accuracy: 0.8542 - val_loss: 0.3668\n",
      "Epoch 4/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 563ms/step - accuracy: 0.9213 - loss: 0.2084 - val_accuracy: 0.8262 - val_loss: 0.4245\n",
      "Epoch 5/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 562ms/step - accuracy: 0.9461 - loss: 0.1488 - val_accuracy: 0.8582 - val_loss: 0.3759\n",
      "Epoch 1/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m589s\u001b[0m 937ms/step - accuracy: 0.7100 - loss: 0.5392 - val_accuracy: 0.8402 - val_loss: 0.3787\n",
      "Epoch 2/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m557s\u001b[0m 891ms/step - accuracy: 0.8805 - loss: 0.2997 - val_accuracy: 0.8516 - val_loss: 0.3561\n",
      "Epoch 3/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m552s\u001b[0m 883ms/step - accuracy: 0.9274 - loss: 0.1918 - val_accuracy: 0.8286 - val_loss: 0.4044\n",
      "Epoch 4/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m637s\u001b[0m 1s/step - accuracy: 0.9415 - loss: 0.1580 - val_accuracy: 0.8570 - val_loss: 0.3955\n",
      "Epoch 1/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m690s\u001b[0m 1s/step - accuracy: 0.6984 - loss: 0.5573 - val_accuracy: 0.6130 - val_loss: 0.6504\n",
      "Epoch 2/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m670s\u001b[0m 1s/step - accuracy: 0.8291 - loss: 0.3923 - val_accuracy: 0.8402 - val_loss: 0.3796\n",
      "RNN Model - Loss: 0.5144959688186646, Accuracy: 0.7734799981117249\n",
      "LSTM Model - Loss: 0.38271859288215637, Accuracy: 0.8461599946022034\n",
      "Bidirectional LSTM Model - Loss: 0.3497701585292816, Accuracy: 0.8529199957847595\n",
      "Deep LSTM Model - Loss: 0.65118408203125, Accuracy: 0.6050000190734863\n",
      "The best model is: Bidirectional LSTM with accuracy of 0.8529199957847595\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, Bidirectional, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Завантаження даних\n",
    "max_features = 10000  # Кількість унікальних слів\n",
    "maxlen = 500  # Максимальна довжина рецензії\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "# Загальні параметри моделі\n",
    "embedding_size = 128\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# 1. Simple RNN Model\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(Embedding(max_features, embedding_size, input_length=maxlen))\n",
    "rnn_model.add(SimpleRNN(128))\n",
    "rnn_model.add(Dense(1, activation='sigmoid'))\n",
    "rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 2. LSTM Model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(max_features, embedding_size, input_length=maxlen))\n",
    "lstm_model.add(LSTM(128))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 3. Bidirectional LSTM Model\n",
    "bi_lstm_model = Sequential()\n",
    "bi_lstm_model.add(Embedding(max_features, embedding_size, input_length=maxlen))\n",
    "bi_lstm_model.add(Bidirectional(LSTM(128)))\n",
    "bi_lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "bi_lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 4. Deep LSTM Model\n",
    "deep_lstm_model = Sequential()\n",
    "deep_lstm_model.add(Embedding(max_features, embedding_size, input_length=maxlen))\n",
    "deep_lstm_model.add(LSTM(128, return_sequences=True))\n",
    "deep_lstm_model.add(LSTM(128))\n",
    "deep_lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "deep_lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Навчання моделей\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "history_rnn = rnn_model.fit(x_train, y_train, validation_split=0.2, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])\n",
    "history_lstm = lstm_model.fit(x_train, y_train, validation_split=0.2, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])\n",
    "history_bi_lstm = bi_lstm_model.fit(x_train, y_train, validation_split=0.2, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])\n",
    "history_deep_lstm = deep_lstm_model.fit(x_train, y_train, validation_split=0.2, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])\n",
    "\n",
    "# Оцінка моделей\n",
    "rnn_eval = rnn_model.evaluate(x_test, y_test, verbose=0)\n",
    "lstm_eval = lstm_model.evaluate(x_test, y_test, verbose=0)\n",
    "bi_lstm_eval = bi_lstm_model.evaluate(x_test, y_test, verbose=0)\n",
    "deep_lstm_eval = deep_lstm_model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"RNN Model - Loss: {rnn_eval[0]}, Accuracy: {rnn_eval[1]}\")\n",
    "print(f\"LSTM Model - Loss: {lstm_eval[0]}, Accuracy: {lstm_eval[1]}\")\n",
    "print(f\"Bidirectional LSTM Model - Loss: {bi_lstm_eval[0]}, Accuracy: {bi_lstm_eval[1]}\")\n",
    "print(f\"Deep LSTM Model - Loss: {deep_lstm_eval[0]}, Accuracy: {deep_lstm_eval[1]}\")\n",
    "\n",
    "# Висновки\n",
    "results = {\n",
    "    \"RNN\": rnn_eval[1],\n",
    "    \"LSTM\": lstm_eval[1],\n",
    "    \"Bidirectional LSTM\": bi_lstm_eval[1],\n",
    "    \"Deep LSTM\": deep_lstm_eval[1]\n",
    "}\n",
    "\n",
    "best_model = max(results, key=results.get)\n",
    "print(f\"The best model is: {best_model} with accuracy of {results[best_model]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Згідно отриманих результатів модель двосторонньої LSTM показала найкращу продуктивність з точністю 0.8529.\n",
    "Впринципі це очікувано, оскільки двосторонні LSTM можуть захоплювати залежності в послідовностях з обох напрямків, що робить їх більш потужними для задач, де контекст з обох кінців послідовності є важливим."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
