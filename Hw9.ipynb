{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В якості домашнього завдання вам пропонується створити нейронну мережу за допомогою механізмів Keras, яка буде класифікувати товари із датасету fasion_mnist.\n",
    "\n",
    "Вам належить запропонувати свою власну архітектуру мережі. Точність найнаївнішої, але адекватної нейромережі становить приблизно 91%. Точність вашої моделі повинна бути не нижчою за цей показник. Щоб досягти таких значень вам знадобиться поекспериментувати з гіперпараметрами мережі:\n",
    "\n",
    "кількість шарів;\n",
    "кількість нейронів;\n",
    "функції активації;\n",
    "кількість епох;\n",
    "розмір батчу;\n",
    "вибір оптимізатора;\n",
    "різні техніки регуляризації і т.д.\n",
    "\n",
    "Використайте вивчені техніки виявлення проблем навчання нейронної мережі, і потім поекспериментуйте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 16:38:21.057954: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.6751 - loss: 0.9159 - val_accuracy: 0.8446 - val_loss: 0.4260\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8405 - loss: 0.4465 - val_accuracy: 0.8569 - val_loss: 0.3956\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8590 - loss: 0.3936 - val_accuracy: 0.8703 - val_loss: 0.3559\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8665 - loss: 0.3687 - val_accuracy: 0.8735 - val_loss: 0.3483\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8696 - loss: 0.3519 - val_accuracy: 0.8753 - val_loss: 0.3499\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8755 - loss: 0.3428 - val_accuracy: 0.8758 - val_loss: 0.3431\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8776 - loss: 0.3280 - val_accuracy: 0.8792 - val_loss: 0.3352\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8833 - loss: 0.3170 - val_accuracy: 0.8763 - val_loss: 0.3455\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8861 - loss: 0.3024 - val_accuracy: 0.8852 - val_loss: 0.3167\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8870 - loss: 0.3014 - val_accuracy: 0.8805 - val_loss: 0.3261\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8887 - loss: 0.2996 - val_accuracy: 0.8890 - val_loss: 0.3112\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8937 - loss: 0.2879 - val_accuracy: 0.8867 - val_loss: 0.3167\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8903 - loss: 0.2888 - val_accuracy: 0.8869 - val_loss: 0.3219\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8955 - loss: 0.2774 - val_accuracy: 0.8885 - val_loss: 0.3163\n",
      "313/313 - 0s - 1ms/step - accuracy: 0.8765 - loss: 0.3425\n",
      "\n",
      "Точність на тестових даних: 0.8765\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# Завантаження датасету\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Нормалізація даних\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Перетворення міток у категоріальний формат\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Додавання шарів\n",
    "model.add(Flatten(input_shape=(28, 28)))  # Перетворення 2D зображень у 1D\n",
    "model.add(Dense(128, activation='relu'))  # Перший прихований шар\n",
    "model.add(Dropout(0.2))                   # Dropout для запобігання перенавчання\n",
    "model.add(Dense(128, activation='relu'))  # Другий прихований шар\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))  # Вихідний шар\n",
    "\n",
    "model.compile(optimizer=Adam(), \n",
    "            loss='categorical_crossentropy', \n",
    "            metrics=['accuracy'])\n",
    "\n",
    "# Використання раннього зупинення для запобігання перенавчання\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "history = model.fit(x_train, y_train, \n",
    "                    epochs=20, \n",
    "                    batch_size=128, \n",
    "                    validation_split=0.2, \n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'\\nТочність на тестових даних: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.4908 - loss: 1.7145 - val_accuracy: 0.7973 - val_loss: 0.7375\n",
      "Epoch 2/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.7521 - loss: 0.8598 - val_accuracy: 0.8297 - val_loss: 0.5844\n",
      "Epoch 3/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.7913 - loss: 0.7349 - val_accuracy: 0.8452 - val_loss: 0.5409\n",
      "Epoch 4/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.8192 - loss: 0.6579 - val_accuracy: 0.8538 - val_loss: 0.5198\n",
      "Epoch 5/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.8248 - loss: 0.6244 - val_accuracy: 0.8597 - val_loss: 0.4971\n",
      "Epoch 6/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 29ms/step - accuracy: 0.8373 - loss: 0.5970 - val_accuracy: 0.8660 - val_loss: 0.4868\n",
      "Epoch 7/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 40ms/step - accuracy: 0.8487 - loss: 0.5624 - val_accuracy: 0.8663 - val_loss: 0.4802\n",
      "Epoch 8/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.8497 - loss: 0.5462 - val_accuracy: 0.8734 - val_loss: 0.4678\n",
      "Epoch 9/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.8559 - loss: 0.5322 - val_accuracy: 0.8720 - val_loss: 0.4688\n",
      "Epoch 10/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - accuracy: 0.8620 - loss: 0.5160 - val_accuracy: 0.8729 - val_loss: 0.4590\n",
      "Epoch 11/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.8633 - loss: 0.4997 - val_accuracy: 0.8673 - val_loss: 0.4742\n",
      "Epoch 12/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.8710 - loss: 0.4879 - val_accuracy: 0.8815 - val_loss: 0.4434\n",
      "Epoch 13/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8726 - loss: 0.4754 - val_accuracy: 0.8805 - val_loss: 0.4410\n",
      "Epoch 14/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.8762 - loss: 0.4665 - val_accuracy: 0.8830 - val_loss: 0.4426\n",
      "Epoch 15/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8781 - loss: 0.4543 - val_accuracy: 0.8827 - val_loss: 0.4357\n",
      "Epoch 16/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 29ms/step - accuracy: 0.8782 - loss: 0.4572 - val_accuracy: 0.8881 - val_loss: 0.4267\n",
      "Epoch 17/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.8841 - loss: 0.4408 - val_accuracy: 0.8852 - val_loss: 0.4235\n",
      "Epoch 18/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.8839 - loss: 0.4335 - val_accuracy: 0.8882 - val_loss: 0.4204\n",
      "Epoch 19/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.8840 - loss: 0.4288 - val_accuracy: 0.8889 - val_loss: 0.4150\n",
      "Epoch 20/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.8863 - loss: 0.4236 - val_accuracy: 0.8873 - val_loss: 0.4191\n",
      "Epoch 21/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.8905 - loss: 0.4131 - val_accuracy: 0.8849 - val_loss: 0.4267\n",
      "Epoch 22/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.8894 - loss: 0.4141 - val_accuracy: 0.8904 - val_loss: 0.4138\n",
      "Epoch 23/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8931 - loss: 0.4060 - val_accuracy: 0.8846 - val_loss: 0.4330\n",
      "Epoch 24/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.8953 - loss: 0.3967 - val_accuracy: 0.8877 - val_loss: 0.4161\n",
      "Epoch 25/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8969 - loss: 0.3934 - val_accuracy: 0.8906 - val_loss: 0.4113\n",
      "Epoch 26/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8957 - loss: 0.3925 - val_accuracy: 0.8888 - val_loss: 0.4159\n",
      "Epoch 27/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8988 - loss: 0.3823 - val_accuracy: 0.8905 - val_loss: 0.4074\n",
      "Epoch 28/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.9037 - loss: 0.3726 - val_accuracy: 0.8902 - val_loss: 0.4095\n",
      "Epoch 29/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9009 - loss: 0.3754 - val_accuracy: 0.8930 - val_loss: 0.4082\n",
      "Epoch 30/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9034 - loss: 0.3643 - val_accuracy: 0.8926 - val_loss: 0.4046\n",
      "Epoch 31/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 30ms/step - accuracy: 0.9061 - loss: 0.3589 - val_accuracy: 0.8909 - val_loss: 0.4095\n",
      "Epoch 32/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.9040 - loss: 0.3645 - val_accuracy: 0.8923 - val_loss: 0.4073\n",
      "Epoch 33/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 30ms/step - accuracy: 0.9086 - loss: 0.3578 - val_accuracy: 0.8948 - val_loss: 0.3988\n",
      "Epoch 34/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 30ms/step - accuracy: 0.9092 - loss: 0.3514 - val_accuracy: 0.8928 - val_loss: 0.4061\n",
      "Epoch 35/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 29ms/step - accuracy: 0.9099 - loss: 0.3468 - val_accuracy: 0.8938 - val_loss: 0.4052\n",
      "Epoch 36/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.9131 - loss: 0.3401 - val_accuracy: 0.8915 - val_loss: 0.4064\n",
      "Epoch 37/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9110 - loss: 0.3402 - val_accuracy: 0.8964 - val_loss: 0.3966\n",
      "Epoch 38/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 30ms/step - accuracy: 0.9125 - loss: 0.3404 - val_accuracy: 0.8963 - val_loss: 0.3978\n",
      "Epoch 39/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - accuracy: 0.9168 - loss: 0.3259 - val_accuracy: 0.8904 - val_loss: 0.4203\n",
      "Epoch 40/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.9134 - loss: 0.3322 - val_accuracy: 0.8921 - val_loss: 0.4097\n",
      "Epoch 41/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.9137 - loss: 0.3313 - val_accuracy: 0.8968 - val_loss: 0.3946\n",
      "Epoch 42/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.9167 - loss: 0.3208 - val_accuracy: 0.8972 - val_loss: 0.3935\n",
      "Epoch 43/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9173 - loss: 0.3266 - val_accuracy: 0.8982 - val_loss: 0.4000\n",
      "Epoch 44/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.9193 - loss: 0.3157 - val_accuracy: 0.8991 - val_loss: 0.3982\n",
      "Epoch 45/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.9206 - loss: 0.3129 - val_accuracy: 0.8939 - val_loss: 0.4103\n",
      "Epoch 46/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9208 - loss: 0.3142 - val_accuracy: 0.8948 - val_loss: 0.4062\n",
      "Epoch 47/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.9209 - loss: 0.3089 - val_accuracy: 0.8917 - val_loss: 0.4157\n",
      "Epoch 48/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9225 - loss: 0.3089 - val_accuracy: 0.8998 - val_loss: 0.3923\n",
      "Epoch 49/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.9227 - loss: 0.3030 - val_accuracy: 0.8957 - val_loss: 0.4033\n",
      "Epoch 50/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 30ms/step - accuracy: 0.9228 - loss: 0.2995 - val_accuracy: 0.8939 - val_loss: 0.4001\n",
      "Epoch 51/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9244 - loss: 0.2989 - val_accuracy: 0.8924 - val_loss: 0.4072\n",
      "Epoch 52/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9242 - loss: 0.2992 - val_accuracy: 0.8956 - val_loss: 0.4039\n",
      "Epoch 53/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - accuracy: 0.9273 - loss: 0.2942 - val_accuracy: 0.8984 - val_loss: 0.3987\n",
      "Epoch 54/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - accuracy: 0.9258 - loss: 0.2895 - val_accuracy: 0.8916 - val_loss: 0.4101\n",
      "Epoch 55/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - accuracy: 0.9261 - loss: 0.2895 - val_accuracy: 0.8976 - val_loss: 0.3926\n",
      "Epoch 56/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - accuracy: 0.9269 - loss: 0.2904 - val_accuracy: 0.8945 - val_loss: 0.4074\n",
      "Epoch 57/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9300 - loss: 0.2814 - val_accuracy: 0.8969 - val_loss: 0.3999\n",
      "Epoch 58/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - accuracy: 0.9298 - loss: 0.2780 - val_accuracy: 0.8991 - val_loss: 0.3956\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8908 - loss: 0.4208\n",
      "\n",
      "Точність на тестових даних: 0.8908\n"
     ]
    }
   ],
   "source": [
    "# Покращення \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Завантаження датасету\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Нормалізація даних\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Перетворення міток у категоріальний формат\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Додавання шарів\n",
    "model.add(Flatten(input_shape=(28, 28)))  # Перетворення 2D зображень у 1D\n",
    "model.add(Dense(512, kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\n",
    "model.add(LeakyReLU(negative_slope=0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(256, kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\n",
    "model.add(LeakyReLU(negative_slope=0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(128, kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\n",
    "model.add(LeakyReLU(negative_slope=0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(64, kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\n",
    "model.add(LeakyReLU(negative_slope=0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))  # Вихідний шар\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "            loss='categorical_crossentropy', \n",
    "            metrics=['accuracy'])\n",
    "\n",
    "# Використання раннього зупинення для запобігання перенавчання\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(x_train, y_train, \n",
    "                    epochs=100, \n",
    "                    batch_size=128, \n",
    "                    validation_split=0.2, \n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'\\nТочність на тестових даних: {test_acc:.4f}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
